---
layout: post
title: flink数据传输
categories: [flink]
description: flink
keywords: flink
---

https://cwiki.apache.org/confluence/display/FLINK/Data+exchange+between+tasks

Flink中的数据交换基于以下设计原则构建：

数据交换（即，为了启动交换而传递的消息）的控制流是由接收方发起的，就像原始的MapReduce一样。
用于数据交换的数据流，即通过导线的实际数据传输，是通过IntermediateResult的概念抽象的，并且是可插入的。这意味着该系统可以使用同一实现同时支持流数据传输和批处理数据传输。
数据交换涉及多个对象，包括：

主节点JobManager负责安排任务，恢复和协调，并通过ExecutionGraph数据结构掌握工作的概况。

TaskManagers，工作节点。TaskManager（TM）在线程中同时执行许多任务。每个TM还包含一个CommunicationManager（CM-在任务之间共享）和一个MemoryManager（MM-在任务之间共享）。TM可以通过需要时创建的常规TCP连接相互交换数据。

请注意，在Flink中，通过网络交换数据的是TaskManager，而不是任务，即，驻留在同一TM中的任务之间的数据交换是通过一个网络连接复用的

![data-exchange-1](/images/posts/data-exchange-1.png)

ExecutionGraph：执行图是一个数据结构，其中包含有关作业计算的“基本事实”。它由代表计算任务的顶点（ExecutionVertex）和代表任务产生的数据的中间结果（IntermediateResultPartition）组成。顶点通过ExecutionEdges（EE）链接到它们消耗的中间结果

![data-exchanges2](/images/posts/data-exchanges2.png)

这些是JobManager中存在的逻辑数据结构。它们具有与运行时等效的结构，这些结构负责TaskManager上的实际数据处理。与IntermediateResultPartition等效的运行时称为ResultPartition。

ResultPartition（RP）表示BufferWriter写入的数据块，即，单个任务产生的数据块。RP是结果子分区（RS）的集合。这是为了区分发往不同接收者的数据，例如，在用于减法或合并的分区混洗的情况下。

ResultSubpartition（RS）代表操作员创建的数据的一个分区，以及将数据转发给接收操作员的逻辑。RS的特定实现确定了实际的数据传输逻辑，这是可插拔的机制，它使系统能够支持各种数据传输。例如，PipelinedSubpartition是支持流数据交换的管道实现。SpillableSubpartition是一个阻止实现，以支持批量数据交换。

InputGate：接收方RP的逻辑等效项。它负责收集数据缓冲区并将其移交给上游。

InputChannel：接收方RS的逻辑等效项。它负责为特定分区收集数据缓冲区。

缓冲区：请参阅https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=53741525

序列化器和反序列化器将类型化的记录可靠地转换为原始字节缓冲区，反之亦然，处理跨越多个缓冲区的记录等。

# 数据交换的控制流程

![data-exchange3](/images/posts/data-exchange3.png)

该图表示具有两个并行任务的简单map-reduce作业。我们有两个TaskManager，两个任务（一个映射任务和一个reduce任务）在两个不同的节点中运行，一个JobManager在第三个节点中运行。我们专注于任务M1和R2之间转移的启动。数据传输使用粗箭头表示，消息使用细箭头表示。首先，M1产生一个ResultPartition（RP1）（箭头1）。当RP可供消费时（我们稍后再讨论），它会通知JobManager（箭头2）。JobManager通知该分区（任务R1和R2）的预期接收者该分区已准备就绪。如果尚未安排接收方，则实际上将触发任务的部署（箭头3a，3b）。然后，接收者将向RP请求数据（箭头4a和4b）。这将在本地（情况5a）或通过TaskManagers的网络堆栈（5b）启动任务之间的数据传输（箭头5a和5b）。当RP决定将其可用性通知JobManager时，该过程具有一定的自由度。例如，如果RP1在通知JM之前完全产生了自身（并且可能已写入文件），则数据交换大致相当于Hadoop中实现的批量交换。如果RP1在产生第一个记录后立即通知JM，则说明我们进行了流数据交换。当RP决定将其可用性通知JobManager时，该过程具有一定的自由度。例如，如果RP1在通知JM之前完全产生了自身（并且可能已写入文件），则数据交换大致相当于Hadoop中实现的批量交换。如果RP1在产生第一个记录后立即通知JM，则说明我们进行了流数据交换。当RP决定将其可用性通知JobManager时，该过程具有一定的自由度。例如，如果RP1在通知JM之前完全产生了自身（并且可能已写入文件），则数据交换大致相当于Hadoop中实现的批量交换。如果RP1在产生第一个记录后立即通知JM，则说明我们进行了流数据交换。

# 在两个任务之间传输字节缓冲区

![data-exchange4](/images/posts/data-exchange4.png)

此图更详细地介绍了数据记录从生产者运送到消费者时的生命周期。最初，MapDriver会生成记录（由收集器收集），这些记录将传递到RecordWriter对象。RecordWriters包含许多序列化程序（RecordSerializer对象），每个使用方任务一个可能会消耗这些记录的序列化程序。例如，在随机播放或广播中，序列化器的数量将与使用者任务的数量一样多。ChannelSelector选择一个或多个串行器以放置记录。例如，如果广播记录，则将它们放置在每个序列化程序中。如果记录是按哈希分区的，则ChannelSelector将评估记录上的哈希值并选择适当的序列化程序。

序列化程序将记录序列化为它们的二进制表示形式，并将它们放置在固定大小的缓冲区中（记录可以跨越多个缓冲区）。这些缓冲器和切换到BufferWriter并写出到一个ResultPartition（RP）。RP由几个子分区（ResultSubpartitions-RS）组成，这些子分区收集特定使用者的缓冲区。在图中，该缓冲区发往第二个减速器（在TaskManager 2中），并将其放置在RS2中。由于这是第一个缓冲区，因此RS2可供使用（请注意，此行为实现了流式改组），并将该事实通知给JobManager。

JobManager查找RS2的使用者，并通知TaskManager 2可用数据块。发送到TM2的消息向下传播到应该接收此缓冲区的InputChannel，后者进而通知RS2可以启动网络传输。然后，RS2将缓冲区移交给TM1的网络堆栈，后者又将其移交给Netty进行运输。网络连接是长期运行的，并且存在于TaskManager之间，而不是单个任务之间。

一旦TM2接收到缓冲区，缓冲区便会通过相似的对象层次结构，从InputChannel（与IRPQ等效的接收方）开始，到达InputGate（包含多个IC），最后在RecordDeserializer中结束，从缓冲区生成类型化的记录，并将其交给接收任务，在这种情况下为ReduceDriver。