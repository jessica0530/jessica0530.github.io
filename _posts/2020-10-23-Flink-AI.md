---
layout: post
title: Flink AI
categories: [flink]
description: Flink AI
keywords: flink
---

连接 https://blog.csdn.net/alitech2017/article/details/104409132/

数据实时化,同样是向数据要价值,AI对数据时效性的要求同大数据是一致的

AI 分为3个部分

## 数据预处理

（也称数据准备/特征工程等）

根据数据预处理后的下游不同，数据预处理可能是批计算也可能是流计算，计算类型和下游一致。在一个典型的离线训练（批计算）和在线预测（流计算）场景下，训练和预测时要求产生输入数据的预处理逻辑是一致的（比如相同的样本拼接逻辑），这里的需求和Lambda架构中的需求一样，因此一个流批统一的引擎会格外有优势。**这样可以避免批作业和流作业使用两个不同的引擎，省去了维护逻辑一致的两套代码的麻烦**。



## 模型训练

AI训练阶段基本上是批计算（离线训练）产生静态模型（Static Model）的过程。这是因为目前绝大多数的模型是基于独立同分布（IID）的统计规律实现的，也就是从大量的训练样本中找到特征和标签之间的统计相关性（Correlation），这些统计相关性通常不会突然变化，因此在一批样本上训练出的数据在另一批具有相同的特征分布的样本上依然适用。



然而这样的离线模型训练产生的静态模型依然可能存在一些问题



样本数据可能随着时间推移会发生分布变化，这种情况下，在线预测的样本分布和训练样本的分布会产生偏移，从而使模型预测的效果变差。因此静态模型通常需要重新训练，这可以是一个定期过程或者通过对样本和模型的预测效果进行监控来实现

在有些场景下，预测阶段的样本分布可能无法在训练阶段就知晓。举例来说，在阿里双十一，微博热搜，高频交易等这类样本分布可能发生无法预测的分布改变的场景下，**如何迅速更新模型来得到更好的预测结果是十分有价值的**





## 推理预测



推理预测环节的环境和计算类型比较丰富，既有批处理（离线预测）又有流处理。流式预测又大致可以分为在线 (Online) 预测和近线 (Nearline) 预测。在线预测通常处于用户访问的关键链路(Critical Path中)，因此对latency的要求极高，比如毫秒级。而近线预测要求略低一些，通常在亚秒级到秒级。目前大多数纯流式分布式计算（Native Stream Processing）引擎可以满足近线数据预处理和预测的需求，而在线数据预处理和预测则通常需要将预测代码写进应用程序内部来满足极致的低延迟要求。因此在线预测的场景也比较少看到大数据引擎的身影。



在这方面Flink的Stateful Function [9] 是一个独特的创新，Stateful Function的设计初衷是在Flink上通过若干有状态的函数来构建一个在线应用，通过它可以做到超低延迟的在线预测服务，这样用户可以在离线，近线和在线三种场景下使用同一套代码同一个引擎来进行数据预处理和预测

![ai-process](/images/posts/ai-process.jpeg)

AI Flow：兼顾流计算的大数据 + AI 顶层工作流抽象和配套服务。

Stateful Function[9]：提供堪比在线应用的超低延迟数据预处理和推理预测。

其中有些是Flink作为流行的大数据引擎的自有功能，比如丰富Connector生态来对接各种外部数据源。另一些则要依靠Flink之外的生态项目来完成，其中比较重要的是AI Flow。它虽然起源于支持AI实时化架构，但是在引擎层并不绑定Flink，而聚焦于顶层的流批统一工作流抽象，旨在为不同平台，不同引擎和不同系统共同服务于AI实时化的架构提供环境支持。

https://flink.apache.org/news/2020/04/07/release-statefun-2.0.0.html#event-driven-database-vs-requestresponse-database



## 基于Apache Flink构建**的事件驱动数据库**

https://github.com/apache/flink-statefun



![stateful_functions_overview-ops](/images/posts/stateful_functions_overview-ops.png)