---
layout: post
title: Yarn
categories: [yarn]
description: Yarn 
keywords: yarn
---

# Yarn 架构 



![Hadoop-YARN-Architecture](/Users/jessica/ideaproject-github/jessica0530.github.io/images/posts/Hadoop-YARN-Architecture.png)

# 往Yarn提交作业

![spark-run-on-yarn](/Users/jessica/ideaproject-github/jessica0530.github.io/images/posts/spark-run-on-yarn.jpg)

# Yarn 的需求

1.可扩展性:可以平滑地扩展至数万节点和并发应用

2.可维护性:保证集群软件的升级与用户应用程序完全解耦

3.多租户:同一个集群多个租户并存,同时支持在多个用户之间细粒度共享单个节点

4.位置感知:对于很多应用来说,将计算移到数据所在位置是一个重大的进步

5.高集群使用率:底层物理资源的高使用率

6.安全和可审计的操作:以安全的,可审计的方式使用集群资源

7.可靠性和可用性:有高度可靠的用户交互,并支持高可用性

8.对编程模型多样性的支持:支持多样化的编程模型,并需要演进为不仅仅以MapReduce为中心的地步

9.灵活的资源模型:支持各个节点的动态资源配置以及灵活的资源模型

10.向后兼容:保持现有MapReduce应用程序的完全向后兼容



# 提高性能的关键

减少数据的移动,需要将计算任务移动到数据所在服务器上,

而不是让数据移动到计算节点上(尽量减少向计算节点转移大数据的操作)

任务可以被调度到他的数据所在HDFS的物理节点上,

但需要暴露集群的底层数据存储布局

这种设计显著减少了网络I/O,并且让大数据I/O都发生在本地磁盘或者同一机架的服务器之间

## ResourceManager

为系统中所有应用的资源分配的决定权,

对应于每个应用程序的ApplicationMaster 是框架相关的,负责与ResourceManager协商资源,以及与NodeManager协同工作来执行和监控任务.



## Scheduler



可插拔的调度器组件,负责为运行中的各个应用分配资源,

分配时会受到容量,队列以及其他因素的制约,

Scheduler是个纯粹的调度器,不负责应用程序的监控和状态跟踪,也不保证在应用程序失败或者硬件失败的情况下对Task的重启. 基于应用程序的资源需求来执行其调度功能,使用了叫做资源Container的抽象概念，

其中包括了多种资源维度,如内存,CPU,磁盘以及网络.

有些是注重容量,有些是注重公平调度

## NodeManager

与每台机器对应的从属进程(slave),负责启动应用程序的Container,监控他们的资源使用情况（CPU,内存,磁盘和网络）,并且报告给ResourceManager

## ApplicationMaster

负责与Scheduler协商合适的Container,跟踪应用程序的状态,以及监控他们的进度

## 资源模型

资源名称(主机名称,机架名称,以及可能的复杂的网络拓扑)

内存量

CPU(核数/类型)

其他资源,如 disk/network I/O,GPU等资源



## ResourceRequest和Container

ResourceRequest<资源名称,优先级,资源需求,Container数>

资源名称:资源期望所在的主机名,机架名, 未来可能支持多个虚拟机,更复杂的网络拓扑

优先级:应用程序内部请求的优先级(而不是多个应用程序之间),优先级会调整应用程序内部各个ResourceRequest的次序

资源需求:是需要的资源量,如内存量,CPU时间

Container数:表示需要这样的Container的数量

## Container规范

YARN Container的启动API是与平台无关的

1.启动Container内进程的命令行

2.环境变量

3.启动Container之前所需的本地资源,如Jar,共享对象,以及辅助的数据文件

4.安全相关的令牌



## Yarn的组件



## Yarn资源模型



## 提高节点资源利用率优化 减少碎片

为了提高节点资源利用率而做的优化叫

延迟调度,为了主资源的公平性,



社区提到的Delay scheduling是根据node的locality进行Delay，

如果分配不满足locality就要等待，而我们则是为了节点资源等待。

一台机器的计算资源其实有很多维度，CPU和内存是最常见的两个，还有网络IO、磁盘IO和GPU等。

以CPU和内存为例，假设现在有一个container，需要申请两个CPU和1G内存，因为Yarn是一个心跳分配机制，如果在11:01时来了一个节点node1，现在闲置了两个CPU和8G内存，理论上是可以分配的，因为我只需要两个CPU和1G内存。如果分配，这台node1的机器就会完全用完CPU，而内存还剩下87%，这部分内存基本就不会有人使用了，这其实是一个非常严重的资源碎片。

如果跳过node1，在一段时间之后，node2来了，node2需要1个CPU，2G内存，这也是可以匹配的，并且将资源分配到node2之后，CPU和内存都会有一些剩余，而这些剩余其实可以被用来调度其他作业，资源利用就会得到很大提升，碎片化会降低很多。这套机制也让我们的集群在高峰时段的资源碎片化小于10%，基本维持在5%左右。



## HDFS 目录打满



集群规模比较大的时候,用户上传的作业和容器log等信息会把HDFS目录打满,

我们会根据Resource Manager里的压力负载将NodeManager心跳设置为动态， 如果Resource Manager负载较大，它会自动地把Node Manager的心跳时间设置得更大一些，这样可以减少一些事件，并减少对Resource Manager的影响。当集群规模较大时，经常会出现Yarn集群与HDFS集群不匹配的情况，比如Yarn集群是ABCD，HDFS集群是BCDE。当按照本地性策略申请资源时，由于没有版本的计算结点，会等待直到超时退出，我们提前把这些信息保存下来，如果申请的资源在集群内一开始就不存在，我们直接降级成any任何节点都可以。



## 资源隔离

更好得资源隔离可以提高在一台机器上同时运行多个作业的效率，我们使用了一种叫NUMA awareness 的技术来做节点内的资源隔离。传统的资源隔离主要通过Cgroup限制使用率。当多个作业同时运行在一台机器上时，虽然作业跑在不同的CPU和内存上，但要共用系统总线带宽和CPU缓存，作业交替运行刷缓存，导致CPU缓存基本就是不可用的状态。



NUMA是一种感知架构，对CPU和内存进行绑定，他们之间有独立的带宽，如果一个CPU访问自己的内存，速度会很快，反之访问其他CPU的内存，速度会很慢。Node Manager起作业时，会直接对作业的CPU和内存进行绑定，这样会有更好的隔离性。最终，我们的生产环境在实测中实现了部分场景15%的效率提升



## Yarn不适合跑流作业



一是端口危机，因为流式作业经常与在线服务交互，期间会频繁建立或断开连接。受限于TCP连接断开机制，如果发生意外中断，系统会等待一段时间才彻底把端口释放，这样可以保证它的完备性，比如经常在Node Manager里重启时会发现端口被占用，经验证又发现端口未被占用。要想解决该问题，一开始就需要考虑特定服务的端口需提前做好预留。因为流式作业需要长时间运行，因此对外部运行时环境依赖是很苛刻的，比如Yarn的Linux container Executor等脚本运行时都需要依赖外部文件，一旦这些文件出问题，就会导致Manager不正常，甚至其上的所有流式容器全部挂掉。



## 申请资源

用户申请资源是一个很头疼的问题，一般用户都会提的比较大，这会造成很多资源浪费，这些资源并没有被真实使用。我们针对这个问题做了两方面努力。首先，我们使用了Dtop，Dtop会实时收集所有容器的物理资源使用情况。

在数据的基础上，我们做了更进一步的实现——动态容器资源调整。首先，我们在Yarn上做了一些开发，因为社区最新版其实已经支持容器动态调整，也就是运行时。我们对这部分功能进行了改进，做了一个比较简单实用的版本。我们通过Dtop对数据进行实时处理，通过Resource预估器对所有应用信息进行实时聚合。如果用户提交一个作业，重启时，Resource预估器可以表明现在需要申请的资源数。在作业运行过程中，它也可以调整流式作业在不同时段，比如高峰期的资源分配

## 离线带宽打满





## Federation机制



我们需要通过该机制对多个同一IDC 集群进行联合，为用户提供统一视图，并提高跨集群资源利用率



## Docker on yarn

为了更好地实现一台物理机之内的资源隔离。


问题

单集群 5000台机器,切主会不会挂掉,抢占机制有没有bug

提高资源利用率 延迟调度- 
如果在11:01时来了一个节点node1，现在闲置了两个CPU和8G内存，理论上是可以分配的，因为我只需要两个CPU和1G内存。如果分配，这台node1的机器就会完全用完CPU，而内存还剩下87%，这部分内存基本就不会有人使用了，这其实是一个非常严重的资源碎片。如果跳过node1，在一段时间之后，node2来了，node2需要1个CPU，2G内存，这也是可以匹配的，并且将资源分配到node2之后，CPU和内存都会有一些剩余，而这些剩余其实可以被用来调度其他作业，资源利用就会得到很大提升，碎片化会降低很多。这套机制也让我们的集群在高峰时段的资源碎片化小于10%，基本维持在5%左右

抢占方面

A队列的资源没有用，而B队列需要的比较多，B队列就会把A的资源挪过去用。如果A在此时提交作业，就会发现队列已经没有资源了，而B作业没有运行完，也不会释放给A，这就需要强调抢占机制，比如把B作业的部分容器杀死从而释放资源给A




问题:

1.k8s 在单集群比如5000台以上机器的规模下,稳定性上,比如在切主等情况下 有没有什么问题,怎么保证稳定性
①若DAG图复杂，那么在JM维护的EG就很复杂，在调度时会出现调度慢，slot.idle.timeout 可以适当调大
 ②若StateBackend 使用JM内存存储，会给JM带来很大的负担，使用Rocksdb增量又会有很多小文件并且RPC很大。建议使用我们自己的Rocksdb增量合并模式（能减少小文件和RPC）
 ③若State不多，还是要用JM存储的话，对JM的资源要申请合理，并且调大akka.framesize
 ④需要初始化的Task过多，有可能下游初始化完成后尝试多次也拉取不到上游Partition会报错PartitionNotFound，建议调大taskmanager.network.request-backoff.max

2.为了提高节点的利用率,他用的是延迟调度,通过调度比较匹配的资源来减少碎片？这个设计是不是只适用于离线作业调度？
应该会延迟作业启动时间,对于实时作业应该不可取吧？这个设计点 你怎么看？

这个设计不太适合生产，会造成大作业抢占资源，自己也起不来，别人也起不来。所以我们自研了声明式调度

3.抢占式资源:B的队列资源会被A队列抢占吗？K8s里面有抢占资源的么,怎么个抢占法,同队列抢占还是 不同队列之间可以抢占
抢占会不会杀死pod

k8s中物理队列资源是强隔离的，两个物理队列的作业不会抢占资源，还有一层逻辑队列，同一个物理队列是可以有多个逻辑队列的，逻辑队列中的作业是可以抢占资源的

4.资源申请的方式: 比如我申请2G2CPU,k8s会不会从2台机器上各申请1G1CPU给我？
不会，pod规格申请时就声明需要的。 （如果可以的话那也是其他模式吧，我们实时并没有用）

5.一个Job申请一个特别大的资源 会不会把集群给卡主,导致其他应用没有资源可用

第二点的时候说到了，会有这个问题，所以我们使用了自研的声明式调度，不会有这个问题，并且更迅速，还能更合理的按优先级调度

6.k8s 有没有什么强依赖的组件,比如之前zk挂了之后,作业全挂了,这种强依赖的情况你们怎么处理

k8s理论上调度完后的作业是没有什么强依赖的，etcd也有一致性保障，我们只解决了flink对zk的强依赖，我们修改了flink对zk的依赖部分，便得不会有zk挂掉就会造成大量作业毁灭性重启，以及会对zk重连造成压力更大的问题

7.用户的作业log信息 把磁盘占满的情况,你们怎么清理的

不运行的pod的日志将由filebeat清理，运行中的flink pod我们做了日志限流

8.资源隔离相关:传统的资源隔离用 cgroup来限制使用率,K8s怎么做的？
当多个作业同时运行在一台机器上时，虽然作业跑在不同的CPU和内存上，但要共用系统总线带宽和CPU缓存，作业交替运行刷缓存，导致CPU缓存基本就是不可用的状态?我们有这种情况吗

kubernetes对于容器级别的隔离其实是交由底层的runtime来负责的，例如docker,当我们指定运行容器所需要资源的request和limit时，docker会为容器设置进程所运行cgroup的cpu.share, cpu.quota, cpu.period, mem.limit等指标来（这题百度吧）

9.Yarn 天生不适合跑流作业,k8s为啥适合？
说是有 端口危机的问题,流作业经常与在线服务交互,会频繁建立连接和断开连接,端口要做预留？k8s对端口要做预留吗?

yarn我们最主要遇到的问题是cpu不能隔离（高版本或者插件可能会提供，但是我们直接用k8s了，k8s提供的生态更好，也更有未来）

10.用户申请资源 一般都会提的比较大,会造成资源浪费,这块怎么规划的
依赖逻辑队列配置Quota，资源超卖，和组长审批，某个用户申请了大的资源，只会占他们组内的资源，一旦用光了，要么申请，要么自己缩

11.动态容器资源调整:我们有没有做这个
对数据进行实时处理，通过Resource预估器对所有应用信息进行实时聚合。
如果用户提交一个作业，重启时，Resource预估器可以表明现在需要申请的资源数。
在作业运行过程中，它也可以调整流式作业在不同时段，比如高峰期的资源分配。

我们runtime支持了auto-scale，不过怎么预估Resource使用以及合理性这个没有去做。这个问题我们更希望通过资源超卖来解决

12.HDFS checkpoint 数据量大的时候,有没有考虑过 修改HDFS来满足大流量的读写

 ①我们的checkpoint是做了可以跨多个集群来写的，所以这个问题并不大对于我们，HDFS端没有什么压力，就算挂了我们也能在对作业0影响的情况下切换集群
    ②除此之外，我们还对KeyedState的hdfs上的文件做了合并小文件以及一个Task(Chain)的多个Rocksdb sst数据文件进行了合并处理，对OperatorState大的作业也可以开启Snappy压缩，降低作业的恢复速率来提高集群的稳定性
    ③我们还在我们的双TM模式上完善了local-recovery和调度时优先调度有local-state的策略，这样的性能都挺好的
    总之目前我们更多的是在flink上做优化，HDFS端并没有达到瓶颈，如果达到瓶颈了，那一般都是flink使用HDFS的姿势有问题，可以进行调整


1.k8s集群维护不是我们管理， 我们只维护flink，在flink规模5000 TaskManager时会遇到以下问题
 ①若DAG图复杂，那么在JM维护的EG就很复杂，在调度时会出现调度慢，slot.idle.timeout 可以适当调大
 ②若StateBackend 使用JM内存存储，会给JM带来很大的负担，使用Rocksdb增量又会有很多小文件并且RPC很大。建议使用我们自己的Rocksdb增量合并模式（能减少小文件和RPC）
 ③若State不多，还是要用JM存储的话，对JM的资源要申请合理，并且调大akka.framesize
 ④需要初始化的Task过多，有可能下游初始化完成后尝试多次也拉取不到上游Partition会报错PartitionNotFound，建议调大taskmanager.network.request-backoff.max

2.这个设计不太适合生产，会造成大作业抢占资源，自己也起不来，别人也起不来。所以我们自研了声明式调度

3.k8s中物理队列资源是强隔离的，两个物理队列的作业不会抢占资源，还有一层逻辑队列，同一个物理队列是可以有多个逻辑队列的，逻辑队列中的作业是可以抢占资源的

4.不会，pod规格申请时就声明需要的。 （如果可以的话那也是其他模式吧，我们实时并没有用）

5.第二点的时候说到了，会有这个问题，所以我们使用了自研的声明式调度，不会有这个问题，并且更迅速，还能更合理的按优先级调度

6.k8s理论上调度完后的作业是没有什么强依赖的，etcd也有一致性保障，我们只解决了flink对zk的强依赖，我们修改了flink对zk的依赖部分，便得不会有zk挂掉就会造成大量作业毁灭性重启，以及会对zk重连造成压力更大的问题

7.不运行的pod的日志将由filebeat清理，运行中的flink pod我们做了日志限流

8.kubernetes对于容器级别的隔离其实是交由底层的runtime来负责的，例如docker,当我们指定运行容器所需要资源的request和limit时，docker会为容器设置进程所运行cgroup的cpu.share, cpu.quota, cpu.period, mem.limit等指标来（这题百度吧）

9.yarn我们最主要遇到的问题是cpu不能隔离（高版本或者插件可能会提供，但是我们直接用k8s了，k8s提供的生态更好，也更有未来）

10.依赖逻辑队列配置Quota，资源超卖，和组长审批，某个用户申请了大的资源，只会占他们组内的资源，一旦用光了，要么申请，要么自己缩

11.我们runtime支持了auto-scale，不过怎么预估Resource使用以及合理性这个没有去做。这个问题我们更希望通过资源超卖来解决

12.Checkpoint相关的优化有很多来解决这些问题
 ①我们的checkpoint是做了可以跨多个集群来写的，所以这个问题并不大对于我们，HDFS端没有什么压力，就算挂了我们也能在对作业0影响的情况下切换集群
    ②除此之外，我们还对KeyedState的hdfs上的文件做了合并小文件以及一个Task(Chain)的多个Rocksdb sst数据文件进行了合并处理，对OperatorState大的作业也可以开启Snappy压缩，降低作业的恢复速率来提高集群的稳定性
    ③我们还在我们的双TM模式上完善了local-recovery和调度时优先调度有local-state的策略，这样的性能都挺好的
    总之目前我们更多的是在flink上做优化，HDFS端并没有达到瓶颈，如果达到瓶颈了，那一般都是flink使用HDFS的姿势有问题，可以进行调整




